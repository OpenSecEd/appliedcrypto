\chapter{Cryptographically verifying photographic images}\label{CameraSignature}
\chapterprecis{%
  This chapter is from DD2520 Applied Crypto, spring 2024, at KTH\@.
}

People often have difficulty distinguishing between AI-generated images and
photographs captured by an actual camera.
To address this, any photographic output from a camera should be digitally
signed by the camera.
It should not be possible for an adversary to obtain a valid camera signature
on an image or video that was not truly captured by the device.
In practice, this means that the image sensor should output raw data that is
immediately signed by the camera's secure hardware before being written to
storage.

An image viewer or video player (for example, a web browser) should be capable
of verifying this signature.
If the signature is missing or invalid, the viewer can warn the user by
highlighting the image (e.g., with a red border) to indicate that the image
might be AI-generated.

\ltnote{%
  The idea is to use more open form of pQBL~\parencite{pQBL}.
  This means that we start with a question.
  This lets the reader think about the problem, try to explore it based on what
  they currently know.
  When we later tell them, the knowledge will be more
  reinforced~\parencite{Szekely1950}.
  This also helps the reader to discern relevant
  aspects~\parencite{NecessaryConditionsOfLearning}.
}
\begin{exercise}\label{CameraSignatureBenefits}
  What are the benefits and limitations of using digital signatures to
  verify photographic authenticity?
\end{exercise}

The main benefit is that we can cryptographically verify that an image was
captured by a specific, trusted camera.
However, a limitation is that we cannot verify that the \emph{content} of the
image is real---an attacker could photograph a printed AI-generated image
and obtain a valid signature.

\begin{exercise}\label{CameraSignatureDesign}
  Outline the cryptographic primitives and protocols needed for this system.
  Discuss the properties required and any potential obstacles.
\end{exercise}

\ltnote{%
  We will now develop the solution iteratively, following the sequence of
  games approach~\parencite{Shoup2004Sequences}.
  Each section addresses one aspect while keeping others invariant,
  creating the contrast needed for
  learning~\parencite{NecessaryConditionsOfLearning}.
}


\section{A first solution: embedded signatures}\label{CameraFirstSolution}

We start with the simplest design that achieves our core goal.

\subsection{Entities and goals}

We can identify the following entities:
\begin{itemize}
  \item The camera~\(C\) that captures images.
  \item The camera manufacturer~\(M\) that produces cameras.
  \item The image viewer~\(V\) (software) that displays images.
  \item The user~\(U\) who views images and wants to know if they are
    authentic.
\end{itemize}

\begin{exercise}
  What is the goal of the system in terms of these entities?
\end{exercise}

The goal is that when user~\(U\) views an image in viewer~\(V\), they can
verify that the image was captured by a genuine camera~\(C\) produced by a
trusted manufacturer~\(M\)---and not generated by AI or other software.

\subsection{Key pair provisioning}

\NewAlgorithm{\Sign}{Sign}
\NewAlgorithm{\Ver}{Verify}
\NewVariable{\SKC}{sk_C}
\NewVariable{\PKC}{pk_C}

Each camera is provisioned with a unique key pair \((\SKC, \PKC)\) during
manufacturing.
The private key~\(\SKC\) is stored in a secure element (similar to a TPM)
within the camera, from which it cannot be extracted.
The public key~\(\PKC\) is embedded in a certificate signed by the
manufacturer.

\begin{exercise}
  How should the signing happen within the camera?
\end{exercise}

\subsection{The signing unit}

The camera contains a dedicated \emph{signing unit}---a secure hardware
component that:
\begin{enumerate}
  \item Receives raw image data directly from the image sensor.
  \item Computes a hash of the raw data.
  \item Signs the hash using~\(\SKC\).
  \item Outputs the signature to be embedded in the image metadata.
\end{enumerate}

Critically, the raw image data flows through the signing unit \emph{before}
it can be modified by any software.
This ensures that only genuine sensor output can be signed.

See \cref{fig:CameraSigningUnit} for the architecture.

\begin{figure}
  \begin{sidecaption}[Camera signing unit architecture]{%
    Raw data from the image sensor flows directly to the signing unit,
    which signs it before the data reaches any modifiable software.
    The signature is embedded in the image file alongside the image data.
  }[fig:CameraSigningUnit]
  \centering
  \begin{tikzpicture}[
    node distance=1.5cm,
    box/.style={rectangle, draw, minimum width=2cm, minimum height=0.8cm},
    arrow/.style={->, >=stealth, thick}
  ]
    \node[box] (sensor) {Image Sensor};
    \node[box, right=of sensor] (signing) {Signing Unit};
    \node[box, right=of signing] (processor) {Image Processor};
    \node[box, below=of processor] (storage) {Storage};

    \draw[arrow] (sensor) -- node[above] {Raw data} (signing);
    \draw[arrow] (signing) -- node[above] {Data + \(\sigma\)} (processor);
    \draw[arrow] (processor) -- (storage);

    \node[below=0.3cm of signing, font=\small] {\(\sigma = \Sign[\SKC, H(\text{data})]\)};
  \end{tikzpicture}
  \end{sidecaption}
\end{figure}

\subsection{Verification in image viewers}

When an image viewer~\(V\) displays an image:
\begin{enumerate}
  \item Extract the signature~\(\sigma\) and camera certificate from the
    image metadata.
  \item Verify the certificate chain back to a trusted manufacturer.
  \item Compute the hash of the image data.
  \item Verify: \(\Ver[\PKC, H(\text{data}), \sigma] \stackrel{?}{=}
    \text{true}\).
\end{enumerate}

If verification fails, the viewer displays a warning (e.g., a red border).

\subsection{Consequences of the design}

\begin{exercise}
  Evaluate this design.
  What are its consequences (advantages and disadvantages)?
\end{exercise}

\begin{enumerate}
  \item The design provides authenticity: we can verify an image came from
    a specific camera.
  \item The camera manufacturer must be trusted---if they leak private
    keys or sign malicious cameras, the system fails.
  \item Edited images lose their signatures.
    Even legitimate edits (cropping, color correction) break verification.
  \item The private key must never leave the camera.
    Side-channel attacks on the signing unit are a concern.
  \item Key revocation is needed if a camera is compromised.
\end{enumerate}


\section{Handling image editing}\label{CameraEditing}

\ltnote{%
  We now address the limitation that any edit breaks the signature.
  This creates contrast with the previous design, helping students discern
  that there is a tension between verifiability and legitimate modification.
}

The first solution fails when images are legitimately edited.
Photographers often adjust exposure, crop images, or apply filters.
These edits break the original signature.

\begin{exercise}
  How can we allow legitimate editing while still providing some form of
  authenticity verification?
\end{exercise}

\subsection{Approach 1: Preserve original alongside edits}

One approach: keep the original signed image and store edits as a
transformation applied to it.
\begin{itemize}
  \item The original image with its signature is preserved.
  \item Edits are recorded as a sequence of operations.
  \item Viewers can verify the original and replay the edits.
\end{itemize}

This is complex and increases file sizes.

\subsection{Approach 2: Perceptual hashing}

Instead of signing the exact image data, we could sign a
\emph{perceptual hash}---a hash that remains stable under minor
modifications.

\begin{exercise}
  What are the trade-offs of perceptual hashing for authenticity?
\end{exercise}

Trade-offs:
\begin{description}
  \item[Robustness] Minor edits don't break verification.
  \item[Security weakness] The boundary between \enquote{minor} and
    \enquote{significant} edits is unclear.
    An attacker might make just enough modifications to change the
    meaning while keeping the perceptual hash valid.
  \item[Collision risk] Perceptual hashes have weaker collision resistance
    than cryptographic hashes.
\end{description}

For high-assurance applications, cryptographic hashes are preferred.

\subsection{Approach 3: Re-signing after editing}

Professional editing software could include the capability to re-sign
images:
\begin{enumerate}
  \item The editor verifies the original signature.
  \item The user makes edits.
  \item The editor signs the new image with its own key.
  \item The metadata records: \enquote{Edited from image signed by
    camera~\(C\), now signed by editor~\(E\).}
\end{enumerate}

This creates a chain of custody but requires trusted editing software.

\subsection{Consequences}

\begin{enumerate}
  \item No perfect solution exists for edited images.
  \item Perceptual hashing weakens security guarantees.
  \item Chain-of-custody approaches require trusted software.
  \item For maximum assurance, only unedited images should be trusted.
\end{enumerate}


\section{Key management and revocation}\label{CameraKeyManagement}

\ltnote{%
  We now address key management, creating contrast with the implicit
  assumption in earlier sections that keys are never compromised.
  Students should discern the importance of key lifecycle management.
}

\begin{exercise}
  What happens if a camera's private key is compromised?
  How should the system handle this?
\end{exercise}

\subsection{Certificate revocation}

When a camera is compromised (lost, stolen, or hacked), its certificate
must be revoked:
\begin{itemize}
  \item The manufacturer maintains a Certificate Revocation List (CRL)
    or an Online Certificate Status Protocol (OCSP) responder.
  \item Image viewers check the revocation status before accepting a
    signature.
  \item Images signed by revoked cameras are flagged as untrusted.
\end{itemize}

\begin{exercise}
  What challenges arise with certificate revocation?
\end{exercise}

Challenges:
\begin{description}
  \item[Timeliness] Revocation information must propagate quickly.
  \item[Offline verification] If the viewer is offline, it cannot check
    current revocation status.
  \item[Backdating] An attacker with a compromised key could backdate
    signatures to before revocation.
\end{description}

\subsection{Key rotation}

For long-lived cameras (e.g., security cameras), periodic key rotation
reduces the impact of potential compromise.
However, this requires a mechanism to update keys securely.

\subsection{PKI structure}

We establish a three-level PKI:
\begin{description}
  \item[Root CA] A trusted authority (possibly a consortium of
    manufacturers) that signs intermediate certificates.
  \item[Manufacturer CA] Each manufacturer has an intermediate certificate
    and signs certificates for their cameras.
  \item[Camera certificates] Each camera has a certificate binding its
    public key to its identity.
\end{description}

See \cref{fig:CameraPKI} for the certificate chain.

\begin{figure}
  \begin{sidecaption}[Camera signature PKI structure]{%
    The certificate chain from root CA to individual cameras.
    Image viewers have the root CA certificate and can verify the
    entire chain.
  }[fig:CameraPKI]
  \centering
  \begin{tikzpicture}[
    node distance=1.2cm,
    box/.style={rectangle, draw, minimum width=3cm, minimum height=0.7cm},
    arrow/.style={->, >=stealth, thick}
  ]
    \node[box] (root) {Root CA};
    \node[box, below left=of root] (mfr1) {Manufacturer 1};
    \node[box, below right=of root] (mfr2) {Manufacturer 2};
    \node[box, below=of mfr1] (cam1) {Camera \(C_1\)};
    \node[box, right=of cam1] (cam2) {Camera \(C_2\)};
    \node[box, below=of mfr2] (cam3) {Camera \(C_3\)};

    \draw[arrow] (root) -- node[left, font=\small] {signs} (mfr1);
    \draw[arrow] (root) -- node[right, font=\small] {signs} (mfr2);
    \draw[arrow] (mfr1) -- (cam1);
    \draw[arrow] (mfr1) -- (cam2);
    \draw[arrow] (mfr2) -- (cam3);
  \end{tikzpicture}
  \end{sidecaption}
\end{figure}

\subsection{Consequences}

\begin{enumerate}
  \item Revocation infrastructure adds complexity and requires network
    connectivity for real-time checking.
  \item Key rotation for embedded devices is challenging.
  \item The root CA is a critical trust anchor; its compromise would be
    catastrophic.
  \item Cross-manufacturer interoperability requires standardization.
\end{enumerate}


\section{Hardware security and side-channel attacks}\label{CameraHardwareSecurity}

\begin{exercise}
  Even with a secure signing unit, what attacks remain possible?
\end{exercise}

\subsection{Side-channel attacks}

The signing unit must protect against:
\begin{description}
  \item[Timing attacks] An attacker measures how long signing takes and
    infers information about the private key.
    Countermeasure: constant-time implementations.
  \item[Power analysis] Measuring power consumption during signing can
    reveal key bits.
    Countermeasure: power-balanced circuits.
  \item[Electromagnetic emanations] Similar to power analysis but using
    EM radiation.
    Countermeasure: shielding.
  \item[Fault injection] Inducing errors (via voltage glitches, lasers)
    to cause signing with known-faulty outputs.
    Countermeasure: redundant computation and detection circuits.
\end{description}

\subsection{Randomness requirements}

\begin{exercise}
  Why is randomness critical for signing operations?
\end{exercise}

Many signature schemes (e.g., ECDSA) require a random nonce for each
signature.
If the nonce is reused or predictable, the private key can be recovered.

The camera must have a high-quality random number generator:
\begin{itemize}
  \item A True Random Number Generator (TRNG) provides entropy.
  \item A CSPRNG (Cryptographically Secure PRNG) extends the entropy.
  \item Alternatively, use deterministic signature schemes like EdDSA
    (Ed25519) or RFC 6979 for ECDSA, which derive the nonce from the
    message and key.
\end{itemize}

\subsection{Consequences}

\begin{enumerate}
  \item Hardware security is expensive and increases device cost.
  \item Side-channel protections must be validated through rigorous
    testing.
  \item Randomness failures have caused real-world cryptographic
    failures (e.g., PlayStation 3 ECDSA nonce reuse).
  \item Deterministic signatures eliminate nonce-related vulnerabilities.
\end{enumerate}


\section{Privacy considerations}\label{CameraPrivacy}

\ltnote{%
  We now address privacy, creating contrast with the assumption that
  authenticity is purely beneficial.
  Students should discern that signatures create privacy trade-offs.
}

\begin{exercise}
  What privacy concerns arise from camera signatures?
\end{exercise}

\subsection{Tracking through signatures}

Each camera has a unique key pair.
If the same camera signs multiple images, they are all linked to that
camera---and potentially to its owner.

Concerns:
\begin{itemize}
  \item Anonymous photography becomes impossible.
  \item Stalkers could link images to identify camera owners.
  \item Law enforcement could track photographers.
\end{itemize}

\subsection{Mitigation approaches}

\begin{description}
  \item[Manufacturer attestation] Instead of camera-specific signatures,
    the manufacturer signs an attestation that \enquote{some genuine
    camera captured this image} without identifying which one.
    This preserves authenticity while improving privacy.
  \item[Group signatures] Multiple cameras share a group key that allows
    verification without identifying the specific signer.
  \item[User control] Allow users to disable signing for personal photos
    while enabling it for photos intended for public trust.
\end{description}

\subsection{Consequences}

\begin{enumerate}
  \item Strong authenticity and strong privacy are in tension.
  \item Manufacturer attestation reduces traceability but increases
    trust in manufacturers.
  \item Group signatures add cryptographic complexity.
  \item User choice requires careful UX design to avoid confusion.
\end{enumerate}


\section{Final design summary}

A complete camera signature system combines:
\begin{enumerate}
  \item A secure signing unit that signs raw sensor data before software
    can modify it.
  \item A PKI with manufacturer certificates and revocation infrastructure.
  \item Hardware protections against side-channel attacks.
  \item Deterministic signatures to avoid nonce-related vulnerabilities.
  \item Privacy controls based on application requirements.
\end{enumerate}

\begin{exercise}
  Consider alternative approaches: How might blockchain technology,
  trusted timestamps, or sensor fusion (e.g., combining camera data with
  GPS and accelerometer readings) enhance this system?
\end{exercise}



\chapter{Detecting bot networks via digital signatures}\label{TwitterSignature}
\chapterprecis{%
  This chapter is from DD2520 Applied Crypto, spring 2024, at KTH\@.
}

In modern social media platforms such as Twitter (now rebranded as X), there is
an increasing challenge in distinguishing between genuine human users and
bot-driven accounts.
A single adversary might control thousands of bot accounts to create an
illusion of widespread support for a particular opinion.
To counteract this, a solution is proposed where all users are required to
digitally sign their tweets and other interactions (such as likes).
This cryptographic requirement ensures that if a person operates multiple bot
accounts, all of their activity is linked via the same digital signature.

\ltnote{%
  We use the same pedagogical approach as in \cref{CameraSignature}:
  try-first questions followed by iterative refinement of the solution.
}
\begin{exercise}\label{BotDetectionGoal}
  What is the goal of using digital signatures for bot detection?
  What properties do we need?
\end{exercise}

The goal is to detect when multiple accounts are controlled by the same
entity.
We need:
\begin{description}
  \item[Linkability] If the same person signs with the same key from
    multiple accounts, we can detect this.
  \item[Unforgeability] A user cannot produce a valid signature without
    their private key.
  \item[Non-repudiation] A user cannot deny having signed a tweet.
\end{description}


\section{A first solution: per-user signatures}\label{BotFirstSolution}

\subsection{Key pair binding}

Each user generates or receives a key pair \((sk_U, pk_U)\) upon
registration.
Every tweet or interaction is signed:
\[
  \sigma = \Sign[sk_U, (\text{tweet\_content}, \text{timestamp},
  \text{account\_id})].
\]

The signature is attached to the tweet.
Anyone can verify the signature using the user's public key.

\begin{exercise}
  How does this help detect bot networks?
\end{exercise}

\subsection{Detecting shared signers}

If the same private key signs tweets from multiple accounts, the
signatures will be verifiable with the same public key.
Observers can scan the platform for accounts whose tweets share the same
signing key---indicating bot network activity.

See \cref{fig:BotDetection} for the detection mechanism.

\begin{figure}
  \begin{sidecaption}[Bot network detection via signatures]{%
    If accounts A, B, and C are all controlled by the same person,
    their tweets will share the same signing key.
    An observer collecting public keys can identify linked accounts.
  }[fig:BotDetection]
  \centering
  \begin{tikzpicture}[
    node distance=1.5cm,
    account/.style={circle, draw, minimum size=1cm},
    key/.style={rectangle, draw, rounded corners, fill=gray!20}
  ]
    \node[account] (a) {A};
    \node[account, right=of a] (b) {B};
    \node[account, right=of b] (c) {C};
    \node[key, below=of b] (key) {\(pk_{\text{attacker}}\)};

    \draw[->] (a) -- (key);
    \draw[->] (b) -- (key);
    \draw[->] (c) -- (key);

    \node[below=0.3cm of key, font=\small] {All accounts linked by shared key};
  \end{tikzpicture}
  \end{sidecaption}
\end{figure}

\subsection{Consequences}

\begin{enumerate}
  \item Bot operators must use different keys for each account to avoid
    detection.
  \item If keys are bound to verified identities (e.g., via government
    ID), obtaining multiple valid keys becomes difficult.
  \item Privacy concern: all tweets by a user are cryptographically
    linked to that user.
\end{enumerate}


\section{Identity binding and attestation}\label{BotIdentityBinding}

\ltnote{%
  We now address how to prevent bot operators from simply generating
  many key pairs---one per fake account.
  This creates contrast with the previous design where anyone could
  generate unlimited keys.
}

\begin{exercise}
  What prevents a bot operator from generating a separate key pair for
  each bot account?
\end{exercise}

The first solution fails if bot operators simply generate unique keys for
each account.
We need to bind keys to verified identities.

\subsection{Approach 1: Certificate authority attestation}

A trusted Certificate Authority (CA) issues certificates only after
identity verification:
\begin{enumerate}
  \item User proves their identity (e.g., via passport, ID card, or
    phone number verification).
  \item The CA issues a certificate binding their public key to their
    verified identity.
  \item Users can only have one valid certificate at a time.
\end{enumerate}

Now, to operate multiple accounts with different keys, a bot operator
would need multiple verified identities---which is expensive or illegal.

\subsection{Approach 2: Device attestation}

Instead of identity verification, we could bind keys to physical devices:
\begin{itemize}
  \item Each smartphone or computer has a secure element with a
    device-specific key.
  \item The platform verifies that tweets are signed by a real device.
  \item Operating bots at scale would require many physical devices.
\end{itemize}

This is similar to Google's SafetyNet/Play Integrity API or Apple's
DeviceCheck.

\begin{exercise}
  What are the trade-offs between identity-based and device-based
  attestation?
\end{exercise}

Trade-offs:
\begin{description}
  \item[Identity-based] Stronger guarantee of one-key-per-person, but
    requires identity verification infrastructure and raises privacy
    concerns.
  \item[Device-based] Preserves pseudonymity, but attackers could
    acquire many devices (device farms) or emulate devices.
\end{description}

\subsection{Consequences}

\begin{enumerate}
  \item Identity binding requires significant infrastructure.
  \item Device attestation is easier to deploy but less robust.
  \item Both approaches have privacy implications.
  \item A hybrid approach (weak device attestation + optional identity
    verification) may balance usability and security.
\end{enumerate}


\section{Privacy-preserving alternatives}\label{BotPrivacy}

\ltnote{%
  We now explore how to detect bots while preserving user privacy.
  This creates contrast with the non-private approaches above.
}

\begin{exercise}
  How can we detect bot networks without revealing user identities or
  linking all of a user's tweets?
\end{exercise}

\subsection{Group signatures}

With group signatures:
\begin{itemize}
  \item All legitimate users share a group key.
  \item Any member can sign, and the signature verifies as coming from
    the group---but not from which member.
  \item A group manager can \enquote{open} signatures to identify the
    signer if abuse is detected.
\end{itemize}

This provides:
\begin{itemize}
  \item Anonymity within the group for normal use.
  \item Accountability when abuse is detected.
  \item Proof that the signer is a legitimate group member (not a bot
    without membership).
\end{itemize}

\begin{exercise}
  What are the challenges with group signatures for social media?
\end{exercise}

Challenges:
\begin{description}
  \item[Scalability] Traditional group signatures don't scale well to
    billions of users.
  \item[Group management] Adding/removing members securely is complex.
  \item[Trust in manager] The group manager can deanonymize anyone.
\end{description}

\subsection{Ring signatures}

Ring signatures allow a user to sign on behalf of a group without
revealing which member signed---and without needing a group manager:
\begin{itemize}
  \item The signer chooses a \enquote{ring} of public keys.
  \item The signature proves the signer owns one of the private keys,
    but not which one.
  \item No one can later identify the actual signer.
\end{itemize}

This provides stronger privacy than group signatures but no
accountability.

\subsection{Consequences}

\begin{enumerate}
  \item Privacy-preserving schemes are computationally more expensive.
  \item Group signatures provide a balance of privacy and accountability.
  \item Ring signatures provide unconditional privacy but no abuse
    detection.
  \item Practical deployment requires careful consideration of the
    privacy/accountability trade-off.
\end{enumerate}


\section{Scalability and performance}\label{BotScalability}

\begin{exercise}
  How do signature verification requirements affect platform
  performance?
\end{exercise}

\subsection{Verification load}

A platform like Twitter handles hundreds of millions of tweets per day.
Each tweet verification requires:
\begin{itemize}
  \item Fetching the signer's public key or certificate.
  \item Performing a signature verification (asymmetric cryptography).
  \item Potentially checking revocation status.
\end{itemize}

\subsection{Performance optimizations}

\begin{description}
  \item[Batch verification] Some signature schemes (e.g., Schnorr,
    BLS) support batch verification of multiple signatures more
    efficiently than individual verification.
  \item[Caching] Frequently used public keys and verification results
    can be cached.
  \item[Probabilistic verification] For bot detection (not per-tweet
    verification), sampling a fraction of tweets may suffice.
  \item[Client-side verification] Offload verification to client apps;
    the platform only stores signatures.
\end{description}

\subsection{Algorithm choice}

\begin{exercise}
  What signature algorithm would you recommend for this system?
\end{exercise}

Considerations:
\begin{description}
  \item[ECDSA (P-256)] Widely supported, reasonable performance.
  \item[EdDSA (Ed25519)] Faster signing and verification, deterministic
    (no nonce issues), growing support.
  \item[BLS signatures] Support aggregation (one signature for many
    signers); useful for group scenarios but require pairing-based
    cryptography.
\end{description}

For a new system, EdDSA (Ed25519) is recommended for its speed,
security, and simplicity.

\subsection{Consequences}

\begin{enumerate}
  \item Mandatory signatures add computational overhead to all
    interactions.
  \item Batch verification and caching are essential for scalability.
  \item Algorithm choice affects both performance and security.
  \item Client-side verification reduces server load but requires
    widespread client support.
\end{enumerate}


\section{Final design summary}

A complete bot detection system via signatures combines:
\begin{enumerate}
  \item Per-user key pairs with signatures on all interactions.
  \item Identity or device attestation to limit key proliferation.
  \item Linkability analysis to detect accounts sharing signing keys.
  \item Optional group signatures for privacy with accountability.
  \item Efficient algorithms (Ed25519) with batch verification for
    scalability.
  \item Revocation infrastructure for compromised or abusive keys.
\end{enumerate}

\begin{exercise}
  Consider the broader implications: How would mandatory signing affect
  free speech, whistleblowing, and political dissent?
  What alternative approaches to bot detection might avoid these
  concerns?
\end{exercise}
