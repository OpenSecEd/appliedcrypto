\chapter{Cryptographically verifying photographic images}\label{CameraSignature}
\chapterprecis{%
  This chapter is from DD2520 Applied Crypto, spring 2024, at KTH\@.
}

People often have difficulty distinguishing between AI-generated images and
photographs captured by an actual camera.
To address this, any photographic output from a camera should be digitally
signed by the camera.
It should not be possible for an adversary to obtain a valid camera signature
on an image or video that was not truly captured by the device.
In practice, this means that the image sensor should output raw data that is
immediately signed by the camera's secure hardware before being written to
storage.

An image viewer or video player (for example, a web browser) should be capable
of verifying this signature.
If the signature is missing or invalid, the viewer can warn the user by
highlighting the image (e.g., with a red border) to indicate that the image
might be AI-generated.

\ltnote{%
  The idea is to use more open form of pQBL~\parencite{pQBL}.
  This means that we start with a question.
  This lets the reader think about the problem, try to explore it based on what
  they currently know.
  When we later tell them, the knowledge will be more
  reinforced~\parencite{Szekely1950}.
  This also helps the reader to discern relevant
  aspects~\parencite{NecessaryConditionsOfLearning}.
}
\begin{exercise}\label{CameraSignatureBenefits}
  What are the benefits and limitations of using digital signatures to
  verify photographic authenticity?
\end{exercise}

The main benefit is that we can cryptographically verify that an image was
captured by a specific, trusted camera.
However, a limitation is that we cannot verify that the \emph{content} of the
image is real---an attacker could photograph a printed AI-generated image
and obtain a valid signature.

\begin{exercise}\label{CameraSignatureDesign}
  Outline the cryptographic primitives and protocols needed for this system.
  Discuss the properties required and any potential obstacles.
\end{exercise}

\ltnote{%
  We will now develop the solution iteratively, following the sequence of
  games approach~\parencite{Shoup2004Sequences}.
  Each section addresses one aspect while keeping others invariant,
  creating the contrast needed for
  learning~\parencite{NecessaryConditionsOfLearning}.
}


\section{A first solution: embedded signatures}\label{CameraFirstSolution}

We start with the simplest design that achieves our core goal.

\subsection{Entities and goals}

We can identify the following entities:
\begin{itemize}
  \item The camera~\(C\) that captures images.
  \item The camera manufacturer~\(M\) that produces cameras.
  \item The image viewer~\(V\) (software) that displays images.
  \item The user~\(U\) who views images and wants to know if they are
    authentic.
\end{itemize}

\begin{exercise}
  What is the goal of the system in terms of these entities?
\end{exercise}

The goal is that when user~\(U\) views an image in viewer~\(V\), they can
verify that the image was captured by a genuine camera~\(C\) produced by a
trusted manufacturer~\(M\)---and not generated by AI or other software.

\subsection{Key pair provisioning}

\NewAlgorithm{\Sign}{Sign}
\NewAlgorithm{\Ver}{Verify}
\NewVariable{\SKC}{sk_C}
\NewVariable{\PKC}{pk_C}

Each camera is provisioned with a unique key pair \((\SKC, \PKC)\) during
manufacturing.
The private key~\(\SKC\) is stored in a secure element (similar to a TPM)
within the camera, from which it cannot be extracted.
The public key~\(\PKC\) is embedded in a certificate signed by the
manufacturer.

\begin{exercise}
  How should the signing happen within the camera?
\end{exercise}

\subsection{The signing unit}

The camera contains a dedicated \emph{signing unit}---a secure hardware
component that:
\begin{enumerate}
  \item Receives raw image data directly from the image sensor.
  \item Computes a hash of the raw data.
  \item Signs the hash using~\(\SKC\).
  \item Outputs the signature to be embedded in the image metadata.
\end{enumerate}

Critically, the raw image data flows through the signing unit \emph{before}
it can be modified by any software.
This ensures that only genuine sensor output can be signed.

See \cref{fig:CameraSigningUnit} for the architecture.

\begin{figure}
  \begin{sidecaption}[Camera signing unit architecture]{%
    Raw data from the image sensor flows directly to the signing unit,
    which signs it before the data reaches any modifiable software.
    The signature is embedded in the image file alongside the image data.
  }[fig:CameraSigningUnit]
  \centering
  \begin{tikzpicture}[
    node distance=1.5cm,
    box/.style={rectangle, draw, minimum width=2cm, minimum height=0.8cm},
    arrow/.style={->, >=stealth, thick}
  ]
    \node[box] (sensor) {Image Sensor};
    \node[box, right=of sensor] (signing) {Signing Unit};
    \node[box, right=of signing] (processor) {Image Processor};
    \node[box, below=of processor] (storage) {Storage};

    \draw[arrow] (sensor) -- node[above] {Raw data} (signing);
    \draw[arrow] (signing) -- node[above] {Data + \(\sigma\)} (processor);
    \draw[arrow] (processor) -- (storage);

    \node[below=0.3cm of signing, font=\small] {\(\sigma = \Sign[\SKC, H(\text{data})]\)};
  \end{tikzpicture}
  \end{sidecaption}
\end{figure}

\subsection{Verification in image viewers}

When an image viewer~\(V\) displays an image:
\begin{enumerate}
  \item Extract the signature~\(\sigma\) and camera certificate from the
    image metadata.
  \item Verify the certificate chain back to a trusted manufacturer.
  \item Compute the hash of the image data.
  \item Verify: \(\Ver[\PKC, H(\text{data}), \sigma] \stackrel{?}{=}
    \text{true}\).
\end{enumerate}

If verification fails, the viewer displays a warning (e.g., a red border).

\subsection{Consequences of the design}

\begin{exercise}
  Evaluate this design.
  What are its consequences (advantages and disadvantages)?
\end{exercise}

\begin{enumerate}
  \item The design provides authenticity: we can verify an image came from
    a specific camera.
  \item The camera manufacturer must be trusted---if they leak private
    keys or sign malicious cameras, the system fails.
  \item Edited images lose their signatures.
    Even legitimate edits (cropping, color correction) break verification.
  \item The private key must never leave the camera.
    Side-channel attacks on the signing unit are a concern.
  \item Key revocation is needed if a camera is compromised.
\end{enumerate}


\section{Handling image editing}\label{CameraEditing}

\ltnote{%
  We now address the limitation that any edit breaks the signature.
  This creates contrast with the previous design, helping students discern
  that there is a tension between verifiability and legitimate modification.
}

The first solution fails when images are legitimately edited.
Photographers often adjust exposure, crop images, or apply filters.
These edits break the original signature.

\begin{exercise}
  How can we allow legitimate editing while still providing some form of
  authenticity verification?
\end{exercise}

\subsection{Approach 1: Preserve original alongside edits}

One approach: keep the original signed image and store edits as a
transformation applied to it.
\begin{itemize}
  \item The original image with its signature is preserved.
  \item Edits are recorded as a sequence of operations.
  \item Viewers can verify the original and replay the edits.
\end{itemize}

This is complex and increases file sizes.

\subsection{Approach 2: Perceptual hashing}

Instead of signing the exact image data, we could sign a
\emph{perceptual hash}---a hash that remains stable under minor
modifications.

\begin{exercise}
  What are the trade-offs of perceptual hashing for authenticity?
\end{exercise}

Trade-offs:
\begin{description}
  \item[Robustness] Minor edits don't break verification.
  \item[Security weakness] The boundary between \enquote{minor} and
    \enquote{significant} edits is unclear.
    An attacker might make just enough modifications to change the
    meaning while keeping the perceptual hash valid.
  \item[Collision risk] Perceptual hashes have weaker collision resistance
    than cryptographic hashes.
\end{description}

For high-assurance applications, cryptographic hashes are preferred.

\subsection{Approach 3: Re-signing after editing}

Professional editing software could include the capability to re-sign
images:
\begin{enumerate}
  \item The editor verifies the original signature.
  \item The user makes edits.
  \item The editor signs the new image with its own key.
  \item The metadata records: \enquote{Edited from image signed by
    camera~\(C\), now signed by editor~\(E\).}
\end{enumerate}

This creates a chain of custody but requires trusted editing software.

\subsection{Consequences}

\begin{enumerate}
  \item No perfect solution exists for edited images.
  \item Perceptual hashing weakens security guarantees.
  \item Chain-of-custody approaches require trusted software.
  \item For maximum assurance, only unedited images should be trusted.
\end{enumerate}


\section{Key management and revocation}\label{CameraKeyManagement}

\ltnote{%
  We now address key management, creating contrast with the implicit
  assumption in earlier sections that keys are never compromised.
  Students should discern the importance of key lifecycle management.
}

\begin{exercise}
  What happens if a camera's private key is compromised?
  How should the system handle this?
\end{exercise}

\subsection{Certificate revocation}

When a camera is compromised (lost, stolen, or hacked), its certificate
must be revoked:
\begin{itemize}
  \item The manufacturer maintains a Certificate Revocation List (CRL)
    or an Online Certificate Status Protocol (OCSP) responder.
  \item Image viewers check the revocation status before accepting a
    signature.
  \item Images signed by revoked cameras are flagged as untrusted.
\end{itemize}

\begin{exercise}
  What challenges arise with certificate revocation?
\end{exercise}

Challenges:
\begin{description}
  \item[Timeliness] Revocation information must propagate quickly.
  \item[Offline verification] If the viewer is offline, it cannot check
    current revocation status.
  \item[Backdating] An attacker with a compromised key could backdate
    signatures to before revocation.
\end{description}

\subsection{Key rotation}

For long-lived cameras (e.g., security cameras), periodic key rotation
reduces the impact of potential compromise.
However, this requires a mechanism to update keys securely.

\subsection{PKI structure}

We establish a three-level PKI:
\begin{description}
  \item[Root CA] A trusted authority (possibly a consortium of
    manufacturers) that signs intermediate certificates.
  \item[Manufacturer CA] Each manufacturer has an intermediate certificate
    and signs certificates for their cameras.
  \item[Camera certificates] Each camera has a certificate binding its
    public key to its identity.
\end{description}

See \cref{fig:CameraPKI} for the certificate chain.

\begin{figure}
  \begin{sidecaption}[Camera signature PKI structure]{%
    The certificate chain from root CA to individual cameras.
    Image viewers have the root CA certificate and can verify the
    entire chain.
  }[fig:CameraPKI]
  \centering
  \begin{tikzpicture}[
    node distance=1.2cm,
    box/.style={rectangle, draw, minimum width=3cm, minimum height=0.7cm},
    arrow/.style={->, >=stealth, thick}
  ]
    \node[box] (root) {Root CA};
    \node[box, below left=of root] (mfr1) {Manufacturer 1};
    \node[box, below right=of root] (mfr2) {Manufacturer 2};
    \node[box, below=of mfr1] (cam1) {Camera \(C_1\)};
    \node[box, right=of cam1] (cam2) {Camera \(C_2\)};
    \node[box, below=of mfr2] (cam3) {Camera \(C_3\)};

    \draw[arrow] (root) -- node[left, font=\small] {signs} (mfr1);
    \draw[arrow] (root) -- node[right, font=\small] {signs} (mfr2);
    \draw[arrow] (mfr1) -- (cam1);
    \draw[arrow] (mfr1) -- (cam2);
    \draw[arrow] (mfr2) -- (cam3);
  \end{tikzpicture}
  \end{sidecaption}
\end{figure}

\subsection{Consequences}

\begin{enumerate}
  \item Revocation infrastructure adds complexity and requires network
    connectivity for real-time checking.
  \item Key rotation for embedded devices is challenging.
  \item The root CA is a critical trust anchor; its compromise would be
    catastrophic.
  \item Cross-manufacturer interoperability requires standardization.
\end{enumerate}


\section{Offline verification}\label{CameraOfflineVerification}

\ltnote{%
  We address the challenge of verifying signatures without network access.
  This creates contrast with the online revocation checking discussed earlier,
  helping students discern that real-world deployment must handle disconnected 
  scenarios.
  Many students discussed this challenge in their submissions.
}

\begin{exercise}
  Image viewers may not always have network connectivity.
  How can they verify signatures and check revocation status when offline?
\end{exercise}

\subsection{The offline verification challenge}

Certificate verification typically requires checking revocation status via CRL
or OCSP\@.
However, cameras are often used in remote locations, and images may be viewed on
devices without internet access:
\begin{itemize}
  \item A journalist in a conflict zone photographs evidence but cannot connect
    to verify until days later.
  \item An airplane passenger views photos on a laptop without Wi-Fi.
  \item A court proceeding requires verification in a secure facility without
    external network access.
\end{itemize}

\subsection{OCSP stapling}

With OCSP stapling, the camera (or a connected device) periodically obtains a
signed OCSP response and embeds it in the image metadata alongside the
signature:
\begin{enumerate}
  \item The camera connects to the OCSP responder when online.
  \item The responder returns a signed statement: \enquote{Certificate~\(C\) was
    valid at time~\(t\).}
  \item This response is embedded in subsequent images.
  \item Viewers can verify the OCSP response offline, trusting it for a limited
    validity period (e.g., 7 days).
\end{enumerate}

\begin{exercise}
  What are the limitations of OCSP stapling for cameras?
\end{exercise}

Limitations:
\begin{description}
  \item[Staleness] The OCSP response has a validity period.
    Images captured after the response expires but before the camera reconnects
    cannot include fresh revocation status.
  \item[Compromise window] If a camera is compromised and its certificate
    revoked, images signed before the camera learns of revocation will have
    stale (valid) OCSP responses.
  \item[Storage overhead] Each image must include the OCSP response, increasing
    file size.
\end{description}

\subsection{Cached CRLs}

An alternative approach caches Certificate Revocation Lists locally:
\begin{itemize}
  \item Image viewers periodically download CRLs when online.
  \item The cached CRL is used for offline verification.
  \item Delta CRLs reduce bandwidth by transmitting only changes since the last
    full CRL.
\end{itemize}

This shifts the burden from the camera to the viewer, but requires viewers to
maintain current CRL caches.

\subsection{Grace periods and trust decisions}

Practical systems must define policies for offline scenarios:
\begin{description}
  \item[Accept with warning] Display images with stale revocation data but warn
    the user that the certificate status could not be verified recently.
  \item[Time-limited trust] Accept signatures verified against OCSP responses or
    CRLs that are less than~\(n\) days old; reject older ones.
  \item[Fail closed vs.\ fail open] Critical applications (legal evidence) may
    reject unverifiable images; casual viewing may accept them with warnings.
\end{description}

\subsection{Consequences}

\begin{enumerate}
  \item Offline verification requires embedding additional data (OCSP responses)
    or maintaining local caches (CRLs).
  \item Staleness creates a window where revoked certificates may appear valid.
  \item Policy decisions about grace periods involve trade-offs between
    usability and security.
  \item The C2PA standard supports OCSP stapling for interoperable offline
    verification.
\end{enumerate}


\section{Hardware security and side-channel attacks}\label{CameraHardwareSecurity}

\begin{exercise}
  Even with a secure signing unit, what attacks remain possible?
\end{exercise}

\subsection{Side-channel attacks}

The signing unit must protect against:
\begin{description}
  \item[Timing attacks] An attacker measures how long signing takes and
    infers information about the private key.
    Countermeasure: constant-time implementations.
  \item[Power analysis] Measuring power consumption during signing can
    reveal key bits.
    Countermeasure: power-balanced circuits.
  \item[Electromagnetic emanations] Similar to power analysis but using
    EM radiation.
    Countermeasure: shielding.
  \item[Fault injection] Inducing errors (via voltage glitches, lasers)
    to cause signing with known-faulty outputs.
    Countermeasure: redundant computation and detection circuits.
\end{description}

\subsection{Randomness requirements}

\begin{exercise}
  Why is randomness critical for signing operations?
\end{exercise}

Many signature schemes (e.g., ECDSA) require a random nonce for each
signature.
If the nonce is reused or predictable, the private key can be recovered.

The camera must have a high-quality random number generator:
\begin{itemize}
  \item A True Random Number Generator (TRNG) provides entropy.
  \item A CSPRNG (Cryptographically Secure PRNG) extends the entropy.
  \item Alternatively, use deterministic signature schemes like EdDSA
    (Ed25519) or RFC 6979 for ECDSA, which derive the nonce from the
    message and key.
\end{itemize}

\subsection{Consequences}

\begin{enumerate}
  \item Hardware security is expensive and increases device cost.
  \item Side-channel protections must be validated through rigorous
    testing.
  \item Randomness failures have caused real-world cryptographic
    failures (e.g., PlayStation 3 ECDSA nonce reuse).
  \item Deterministic signatures eliminate nonce-related vulnerabilities.
\end{enumerate}


\section{Privacy considerations}\label{CameraPrivacy}

\ltnote{%
  We now address privacy, creating contrast with the assumption that
  authenticity is purely beneficial.
  Students should discern that signatures create privacy trade-offs.
}

\begin{exercise}
  What privacy concerns arise from camera signatures?
\end{exercise}

\subsection{Tracking through signatures}

Each camera has a unique key pair.
If the same camera signs multiple images, they are all linked to that
camera---and potentially to its owner.

Concerns:
\begin{itemize}
  \item Anonymous photography becomes impossible.
  \item Stalkers could link images to identify camera owners.
  \item Law enforcement could track photographers.
\end{itemize}

\subsection{Mitigation approaches}

\begin{description}
  \item[Manufacturer attestation] Instead of camera-specific signatures,
    the manufacturer signs an attestation that \enquote{some genuine
    camera captured this image} without identifying which one.
    This preserves authenticity while improving privacy.
  \item[Group signatures] Multiple cameras share a group key that allows
    verification without identifying the specific signer.
  \item[User control] Allow users to disable signing for personal photos
    while enabling it for photos intended for public trust.
\end{description}

\subsection{Consequences}

\begin{enumerate}
  \item Strong authenticity and strong privacy are in tension.
  \item Manufacturer attestation reduces traceability but increases
    trust in manufacturers.
  \item Group signatures add cryptographic complexity.
  \item User choice requires careful UX design to avoid confusion.
\end{enumerate}


\section{Capture environment verification}\label{CameraCaptureEnvironment}

\ltnote{%
  We address a fundamental limitation: signatures prove the image came from a
  camera, but not that the camera photographed \enquote{reality}.
  This creates contrast with the implicit assumption that signed images are
  truthful.
  Students should discern that cryptographic authenticity differs from content
  truthfulness---but also that cryptography provides the \emph{foundation} that
  makes environmental sensing trustworthy.
  Several students and peer reviewers discussed this attack in their
  submissions.
}

\begin{exercise}
  An attacker prints a high-resolution AI-generated image and photographs it
  with a real camera.
  The resulting image has a valid camera signature.
  How can we detect or prevent this attack?
\end{exercise}

\subsection{The photograph-of-photograph attack}

Camera signatures prove \emph{provenance} (which device created the image) but
not \emph{content authenticity} (whether the scene was real).
An attacker can:
\begin{enumerate}
  \item Generate a photorealistic AI image.
  \item Print it at high resolution or display it on a high-quality screen.
  \item Photograph the print/screen with a genuine camera.
  \item Obtain a valid signature on the fake content.
\end{enumerate}

This is a fundamental limitation of cryptographic signatures: they authenticate
the signing process, not the semantic content.
However, cryptography remains essential---it provides the trusted foundation
upon which additional verification techniques can build.

\subsection{The role of cryptography in environmental verification}

\begin{exercise}
  Environmental sensors (depth, GPS, accelerometer) can detect fake scenes.
  But what prevents an attacker from simply fabricating the sensor data?
\end{exercise}

The key insight is that environmental data is only trustworthy if it comes from
a \emph{trusted platform}---and cryptographic signatures provide this trust:
\begin{enumerate}
  \item The camera's secure element holds a private key that cannot be
    extracted.
  \item All sensor data (image, depth map, GPS coordinates, accelerometer
    readings) flows through the secure element.
  \item The secure element signs the \emph{combined} sensor data atomically.
  \item An attacker cannot selectively modify one sensor's data without
    invalidating the signature.
\end{enumerate}

This creates a chain of trust from hardware to end-user:
\begin{description}
  \item[Hardware attestation] The manufacturer certifies that the secure
    element correctly captures and signs sensor data.
  \item[Sensor binding] The signature covers all sensors simultaneously,
    preventing mix-and-match attacks.
  \item[Tamper evidence] Any modification to sensor data (even by the camera's
    own software) breaks the signature.
  \item[End-user verification] The viewer verifies the signature, trusting the
    certificate chain back to the manufacturer.
\end{description}

Without cryptographic signatures, environmental sensor data would be trivially
forgeable.
With signatures, forging sensor data requires compromising the secure
element---a much harder attack.

\subsection{Depth sensing}

Modern cameras can include depth sensors (LiDAR, structured light, or stereo
cameras) that capture 3D information:
\begin{itemize}
  \item A photograph of a printed image or screen produces a flat depth map.
  \item A photograph of a real 3D scene produces varying depth values.
  \item The depth data is signed alongside the image, allowing viewers to detect
    flat subjects.
\end{itemize}

Critically, the depth sensor must be integrated into the trusted signing path:
the secure element signs both the image and the depth map together, ensuring an
attacker cannot substitute a fake depth map for a real one.

\begin{exercise}
  What are the limitations of depth sensing as a countermeasure?
\end{exercise}

Limitations:
\begin{description}
  \item[Cost and complexity] Depth sensors increase camera cost and power
    consumption.
  \item[Range limitations] Many depth sensors work only at short range (a few
    meters), limiting their effectiveness for landscape or distant subjects.
  \item[Sophisticated attacks] An attacker could create a physical 3D model or
    use multiple screens at different depths to produce non-flat depth maps.
  \item[Legitimate flat subjects] Photographs of paintings, documents, or
    screens may be legitimately flat.
\end{description}

\subsection{Environmental sensor fusion}

Cameras can include additional sensors whose data is signed with the image.
The cryptographic signature binds all sensor readings to a single capture event:
\begin{description}
  \item[Accelerometer and gyroscope] Record camera motion during capture.
    A static tripod shot of a print differs from handheld photography.
    The signature proves these readings came from the same device at capture
    time.
  \item[GPS and compass] Record location and orientation.
    Metadata can be cross-referenced with known geography.
    The signature prevents after-the-fact location spoofing.
  \item[Ambient light sensor] Record lighting conditions.
    Flash photography of a print may produce distinctive reflections.
    Signed sensor data proves the lighting reading accompanied the capture.
  \item[Microphone] Record ambient audio during video capture.
    Audio can corroborate location and environment.
    The signature binds audio to video, preventing substitution.
\end{description}

\begin{exercise}
  How might an attacker defeat environmental sensor fusion?
\end{exercise}

Environmental sensors raise the bar but are not foolproof.
However, the attacker must now defeat the \emph{physical} sensors at capture
time---they cannot simply edit the data afterward:
\begin{itemize}
  \item An attacker could simulate camera motion while photographing a print,
    but this requires physical effort during the attack.
  \item GPS spoofing requires specialized equipment and affects the actual GPS
    receiver, not just the metadata.
  \item Sophisticated setups could match environmental conditions, but this
    increases attack complexity and cost.
\end{itemize}

The cryptographic signature transforms the attack from a software problem
(editing metadata) to a physical problem (fooling sensors in real-time).

\subsection{AI-based authenticity detection}

A complementary approach uses machine learning to detect signs of
photograph-of-photograph attacks:
\begin{itemize}
  \item Moiré patterns from photographing screens.
  \item Paper texture or print artifacts.
  \item Lighting inconsistencies between the subject and environment.
  \item Perspective distortions from photographing flat surfaces.
\end{itemize}

These detectors can run alongside signature verification, providing defense in
depth.
However, as AI generation improves, the arms race between generation and
detection continues.

Unlike sensor-based approaches, AI detection does not benefit directly from
cryptographic signatures---it analyzes the image content itself.
However, signatures still play a role: they ensure the image being analyzed is
the same image that was captured, preventing an attacker from running detection
on one image and substituting another.

\subsection{Consequences}

\begin{enumerate}
  \item Cryptographic signatures alone cannot guarantee content truthfulness,
    but they provide the \emph{trusted foundation} for techniques that can.
  \item Depth sensors and environmental sensors raise the attack cost; their
    trustworthiness depends on cryptographic binding to the capture event.
  \item The signature transforms content attacks from software problems
    (metadata editing) to physical problems (fooling sensors).
  \item AI-based detection provides probabilistic assurance; signatures ensure
    the analyzed image is authentic.
  \item Defense in depth---combining cryptographic signatures with multiple
    sensor and detection approaches---is more robust than any single mechanism.
  \item For high-stakes applications (legal evidence, journalism), human
    judgment and contextual verification remain essential, but cryptographic
    verification provides a strong foundation for that judgment.
\end{enumerate}


\section{Final design summary}

A complete camera signature system combines:
\begin{enumerate}
  \item A secure signing unit that signs raw sensor data before software
    can modify it.
  \item A PKI with manufacturer certificates and revocation infrastructure.
  \item Hardware protections against side-channel attacks.
  \item Deterministic signatures to avoid nonce-related vulnerabilities.
  \item Privacy controls based on application requirements.
\end{enumerate}

\begin{exercise}
  Consider alternative approaches: How might blockchain technology,
  trusted timestamps, or sensor fusion (e.g., combining camera data with
  GPS and accelerometer readings) enhance this system?
\end{exercise}


\section{Trusted timestamps and the C2PA standard}\label{CameraTimestamps}

\ltnote{%
  We introduce trusted timestamps to address the problem of backdating.
  This creates contrast with signature-only approaches where an attacker 
  with a compromised key could create signatures dated before the compromise.
  Students should discern that signatures prove \emph{who} but not 
  \emph{when} without additional mechanisms.
}

\begin{exercise}
  A camera signature proves the image came from a specific camera.
  But how do we prove \emph{when} it was taken?
  Why does this matter?
\end{exercise}

\subsection{The timestamp problem}

Camera signatures alone don't prove when an image was captured:
\begin{itemize}
  \item The camera's internal clock can be manipulated.
  \item An attacker with a compromised key could create backdated signatures.
  \item For legal evidence, the time of capture may be as important as 
    authenticity.
\end{itemize}

\subsection{Timestamp authorities}

A Timestamp Authority (TSA) provides cryptographic proof that data existed at 
a specific time:
\begin{enumerate}
  \item The camera (or a connected device) sends a hash of the signed image to 
    the TSA\@.
  \item The TSA signs the hash together with a trusted timestamp.
  \item The timestamp token is embedded in the image metadata.
\end{enumerate}

Now we have two signatures:
\begin{description}
  \item[Camera signature] Proves the image came from camera~\(C\).
  \item[Timestamp signature] Proves the image existed at time~\(t\).
\end{description}

\begin{exercise}
  What are the requirements for a trustworthy TSA?
\end{exercise}

Requirements:
\begin{itemize}
  \item The TSA must have an accurate, tamper-resistant clock (often 
    synchronized via GPS or secure NTP).
  \item The TSA's signing key must be protected in an HSM.
  \item The TSA should be operated by a trusted, independent entity.
  \item Multiple TSAs can provide redundancy and reduce single-point-of-trust.
\end{itemize}

\subsection{The C2PA standard}

The Coalition for Content Provenance and Authenticity (C2PA) has developed an 
industry standard for content authenticity:
\begin{itemize}
  \item Defines metadata formats for embedding signatures and provenance 
    information.
  \item Specifies how editing software can add its own signatures while 
    preserving the chain of custody.
  \item Includes support for trusted timestamps.
  \item Adopted by major camera manufacturers, software vendors, and platforms.
\end{itemize}

Using C2PA provides interoperability: images signed by one manufacturer's 
camera can be verified by any C2PA-compliant viewer.

\subsection{Consequences}

\begin{enumerate}
  \item Trusted timestamps require network connectivity at capture time (or 
    shortly after).
  \item TSA dependency: if the TSA is unavailable or compromised, timestamp 
    verification fails.
  \item The C2PA standard is evolving; implementations must track updates.
  \item Timestamp tokens increase metadata size.
\end{enumerate}


\section{Post-quantum considerations}\label{CameraPostQuantum}

\ltnote{%
  We introduce the quantum computing threat to create contrast with the 
  implicit assumption that current cryptographic algorithms remain secure 
  indefinitely.
  Students should discern that long-term authenticity requires planning for 
  cryptographic transitions.
}

\begin{exercise}
  Photographic evidence may be relevant decades after capture.
  What happens if quantum computers break the signature algorithms used today?
\end{exercise}

\subsection{The quantum threat to signatures}

Our system uses ECDSA or EdDSA for signatures.
Both are vulnerable to Shor's algorithm on a sufficiently powerful quantum 
computer:
\begin{itemize}
  \item An attacker could forge signatures, making any image appear to be from 
    any camera.
  \item Unlike encryption (where \enquote{harvest now, decrypt later} is the 
    threat), signature forgery affects only \emph{future} verification---past 
    signatures were valid at the time they were created.
\end{itemize}

\subsection{Migration strategies}

\begin{description}
  \item[Post-quantum signature algorithms] NIST has standardized ML-DSA 
    (formerly Dilithium) and SLH-DSA (formerly SPHINCS+).
    These resist quantum attacks but have larger signatures (several 
    kilobytes).
  \item[Hybrid signatures] Sign with both a classical algorithm (ECDSA) and a 
    post-quantum algorithm.
    The image is trusted if \emph{either} signature is valid, providing 
    backwards compatibility and future security.
  \item[Cryptographic agility] Design the system to easily swap algorithms 
    when standards evolve.
\end{description}

For cameras deployed today with a 20-year expected lifespan, hybrid signatures 
are prudent.
The C2PA standard supports algorithm agility, making migration feasible.

\subsection{Consequences}

\begin{enumerate}
  \item Post-quantum signatures increase metadata size significantly.
  \item Hybrid approaches require twice the signature computation.
  \item Not all viewers will immediately support new algorithms.
  \item Planning for quantum resistance now avoids costly retrofits later.
\end{enumerate}


\section{Future work and open problems}\label{CameraFutureWork}

Several aspects of camera signature systems remain active areas of development:

\begin{description}
  \item[AI detection integration] Combining cryptographic signatures with AI 
    detection models could provide defense in depth: signatures prove camera 
    origin, while AI detectors flag suspicious content that lacks signatures.
  \item[Sensor fingerprinting] Each image sensor has unique imperfections that 
    create a \enquote{fingerprint} in images.
    This could complement cryptographic signatures by providing a secondary 
    verification mechanism.
  \item[Video streaming] Live video presents additional challenges: signatures 
    must be applied in real-time, and viewers need to verify without 
    downloading the entire stream.
  \item[Decentralized PKI] Blockchain-based certificate management could 
    provide transparency and reduce reliance on centralized CAs.
  \item[Metadata preservation] Images are often stripped of metadata when 
    shared on social media.
    Standards for preserving authenticity information through sharing 
    pipelines are needed.
  \item[Usability studies] How should viewers display verification status?
    Warning fatigue and user understanding are critical concerns.
\end{description}

\begin{exercise}
  Choose one of the topics above and outline how you would approach designing a 
  solution.
  What cryptographic primitives would you use?
  What are the main challenges?
\end{exercise}


\section*{Acknowledgements}

This chapter was written by Daniel Bosk with the assistance of Dan-Claude van 
Thropic.
The following students from DD2520 Applied Cryptography, Spring 2024, 
contributed additional perspectives through their solutions to the INL1Written 
assignment:
Adam Genell,
Adam Hasselwander,
Alex Kaufmann,
Antoine Missue,
Anton Rådberg,
Arber Limani,
Casper Kristiansson,
Daniel Lai Wikström,
Diogo Torres Correia,
Eusebiu Volostiuc,
Felipe Andrés José San Martín Irarrázabal,
Fredrik Gölman,
Gustav Andersson Kasche,
Gustav Henningsson,
Hassan El Ghamri,
Jakub Ruzicka,
Jonas Liley,
Kristina Skrebutenas,
Ludvig Christensen,
Lukas Gamard,
Marco Campione,
Mateus Monteiro Marinheiro,
Max Engman,
Maximilian Mannila,
Mengtian Li,
Mille af Rolén,
Minh Quang Nguyen,
Nicole Wijkman,
Peter Daniel,
Qikun Tian,
Rafael Mealha Fino Serra e Oliveira,
Richard Palm,
Roni Henareh,
Sam Maltin,
Sina Khoraman,
Sofia Edvardsson,
Tilda Jansson,
Tomi Toma,
Tom Sorger,
Viktor Fornstad,
and
Viktor Johansson Baurne.


\chapter{Detecting bot networks via digital signatures}\label{TwitterSignature}
\chapterprecis{%
  This chapter is from DD2520 Applied Crypto, spring 2024, at KTH\@.
}

In modern social media platforms such as Twitter (now rebranded as X), there is
an increasing challenge in distinguishing between genuine human users and
bot-driven accounts.
A single adversary might control thousands of bot accounts to create an
illusion of widespread support for a particular opinion.
To counteract this, a solution is proposed where all users are required to
digitally sign their tweets and other interactions (such as likes).
This cryptographic requirement ensures that if a person operates multiple bot
accounts, all of their activity is linked via the same digital signature.

\ltnote{%
  We use the same pedagogical approach as in \cref{CameraSignature}:
  try-first questions followed by iterative refinement of the solution.
}
\begin{exercise}\label{BotDetectionGoal}
  What is the goal of using digital signatures for bot detection?
  What properties do we need?
\end{exercise}

The goal is to detect when multiple accounts are controlled by the same
entity.
We need:
\begin{description}
  \item[Linkability] If the same person signs with the same key from
    multiple accounts, we can detect this.
  \item[Unforgeability] A user cannot produce a valid signature without
    their private key.
  \item[Non-repudiation] A user cannot deny having signed a tweet.
\end{description}


\section{A first solution: per-user signatures}\label{BotFirstSolution}

\subsection{Key pair binding}

Each user generates or receives a key pair \((sk_U, pk_U)\) upon
registration.
Every tweet or interaction is signed:
\[
  \sigma = \Sign[sk_U, (\text{tweet\_content}, \text{timestamp},
  \text{account\_id})].
\]

The signature is attached to the tweet.
Anyone can verify the signature using the user's public key.

\begin{exercise}
  How does this help detect bot networks?
\end{exercise}

\subsection{Detecting shared signers}

If the same private key signs tweets from multiple accounts, the
signatures will be verifiable with the same public key.
Observers can scan the platform for accounts whose tweets share the same
signing key---indicating bot network activity.

See \cref{fig:BotDetection} for the detection mechanism.

\begin{figure}
  \begin{sidecaption}[Bot network detection via signatures]{%
    If accounts A, B, and C are all controlled by the same person,
    their tweets will share the same signing key.
    An observer collecting public keys can identify linked accounts.
  }[fig:BotDetection]
  \centering
  \begin{tikzpicture}[
    node distance=1.5cm,
    account/.style={circle, draw, minimum size=1cm},
    key/.style={rectangle, draw, rounded corners, fill=gray!20}
  ]
    \node[account] (a) {A};
    \node[account, right=of a] (b) {B};
    \node[account, right=of b] (c) {C};
    \node[key, below=of b] (key) {\(pk_{\text{attacker}}\)};

    \draw[->] (a) -- (key);
    \draw[->] (b) -- (key);
    \draw[->] (c) -- (key);

    \node[below=0.3cm of key, font=\small] {All accounts linked by shared key};
  \end{tikzpicture}
  \end{sidecaption}
\end{figure}

\subsection{Consequences}

\begin{enumerate}
  \item Bot operators must use different keys for each account to avoid
    detection.
  \item If keys are bound to verified identities (e.g., via government
    ID), obtaining multiple valid keys becomes difficult.
  \item Privacy concern: all tweets by a user are cryptographically
    linked to that user.
\end{enumerate}


\section{Identity binding and attestation}\label{BotIdentityBinding}

\ltnote{%
  We now address how to prevent bot operators from simply generating
  many key pairs---one per fake account.
  This creates contrast with the previous design where anyone could
  generate unlimited keys.
}

\begin{exercise}
  What prevents a bot operator from generating a separate key pair for
  each bot account?
\end{exercise}

The first solution fails if bot operators simply generate unique keys for
each account.
We need to bind keys to verified identities.

\subsection{Approach 1: Certificate authority attestation}

A trusted Certificate Authority (CA) issues certificates only after
identity verification:
\begin{enumerate}
  \item User proves their identity (e.g., via passport, ID card, or
    phone number verification).
  \item The CA issues a certificate binding their public key to their
    verified identity.
  \item Users can only have one valid certificate at a time.
\end{enumerate}

Now, to operate multiple accounts with different keys, a bot operator
would need multiple verified identities---which is expensive or illegal.

\subsection{Approach 2: Device attestation}

Instead of identity verification, we could bind keys to physical devices:
\begin{itemize}
  \item Each smartphone or computer has a secure element with a
    device-specific key.
  \item The platform verifies that tweets are signed by a real device.
  \item Operating bots at scale would require many physical devices.
\end{itemize}

This is similar to Google's SafetyNet/Play Integrity API or Apple's
DeviceCheck.

\begin{exercise}
  What are the trade-offs between identity-based and device-based
  attestation?
\end{exercise}

Trade-offs:
\begin{description}
  \item[Identity-based] Stronger guarantee of one-key-per-person, but
    requires identity verification infrastructure and raises privacy
    concerns.
  \item[Device-based] Preserves pseudonymity, but attackers could
    acquire many devices (device farms) or emulate devices.
\end{description}

\subsection{Consequences}

\begin{enumerate}
  \item Identity binding requires significant infrastructure.
  \item Device attestation is easier to deploy but less robust.
  \item Both approaches have privacy implications.
  \item A hybrid approach (weak device attestation + optional identity
    verification) may balance usability and security.
\end{enumerate}


\section{Privacy-preserving alternatives}\label{BotPrivacy}

\ltnote{%
  We now explore how to detect bots while preserving user privacy.
  This creates contrast with the non-private approaches above.
}

\begin{exercise}
  How can we detect bot networks without revealing user identities or
  linking all of a user's tweets?
\end{exercise}

\subsection{Group signatures}

With group signatures:
\begin{itemize}
  \item All legitimate users share a group key.
  \item Any member can sign, and the signature verifies as coming from
    the group---but not from which member.
  \item A group manager can \enquote{open} signatures to identify the
    signer if abuse is detected.
\end{itemize}

This provides:
\begin{itemize}
  \item Anonymity within the group for normal use.
  \item Accountability when abuse is detected.
  \item Proof that the signer is a legitimate group member (not a bot
    without membership).
\end{itemize}

\begin{exercise}
  What are the challenges with group signatures for social media?
\end{exercise}

Challenges:
\begin{description}
  \item[Scalability] Traditional group signatures don't scale well to
    billions of users.
  \item[Group management] Adding/removing members securely is complex.
  \item[Trust in manager] The group manager can deanonymize anyone.
\end{description}

\subsection{Ring signatures}

Ring signatures allow a user to sign on behalf of a group without
revealing which member signed---and without needing a group manager:
\begin{itemize}
  \item The signer chooses a \enquote{ring} of public keys.
  \item The signature proves the signer owns one of the private keys,
    but not which one.
  \item No one can later identify the actual signer.
\end{itemize}

This provides stronger privacy than group signatures but no
accountability.

\subsection{Consequences}

\begin{enumerate}
  \item Privacy-preserving schemes are computationally more expensive.
  \item Group signatures provide a balance of privacy and accountability.
  \item Ring signatures provide unconditional privacy but no abuse
    detection.
  \item Practical deployment requires careful consideration of the
    privacy/accountability trade-off.
\end{enumerate}


\section{Scalability and performance}\label{BotScalability}

\begin{exercise}
  How do signature verification requirements affect platform
  performance?
\end{exercise}

\subsection{Verification load}

A platform like Twitter handles hundreds of millions of tweets per day.
Each tweet verification requires:
\begin{itemize}
  \item Fetching the signer's public key or certificate.
  \item Performing a signature verification (asymmetric cryptography).
  \item Potentially checking revocation status.
\end{itemize}

\subsection{Performance optimizations}

\begin{description}
  \item[Batch verification] Some signature schemes (e.g., Schnorr,
    BLS) support batch verification of multiple signatures more
    efficiently than individual verification.
  \item[Caching] Frequently used public keys and verification results
    can be cached.
  \item[Probabilistic verification] For bot detection (not per-tweet
    verification), sampling a fraction of tweets may suffice.
  \item[Client-side verification] Offload verification to client apps;
    the platform only stores signatures.
\end{description}

\subsection{Algorithm choice}

\begin{exercise}
  What signature algorithm would you recommend for this system?
\end{exercise}

Considerations:
\begin{description}
  \item[ECDSA (P-256)] Widely supported, reasonable performance.
  \item[EdDSA (Ed25519)] Faster signing and verification, deterministic
    (no nonce issues), growing support.
  \item[BLS signatures] Support aggregation (one signature for many
    signers); useful for group scenarios but require pairing-based
    cryptography.
\end{description}

For a new system, EdDSA (Ed25519) is recommended for its speed,
security, and simplicity.

\subsection{Consequences}

\begin{enumerate}
  \item Mandatory signatures add computational overhead to all
    interactions.
  \item Batch verification and caching are essential for scalability.
  \item Algorithm choice affects both performance and security.
  \item Client-side verification reduces server load but requires
    widespread client support.
\end{enumerate}


\section{Final design summary}

A complete bot detection system via signatures combines:
\begin{enumerate}
  \item Per-user key pairs with signatures on all interactions.
  \item Identity or device attestation to limit key proliferation.
  \item Linkability analysis to detect accounts sharing signing keys.
  \item Optional group signatures for privacy with accountability.
  \item Efficient algorithms (Ed25519) with batch verification for
    scalability.
  \item Revocation infrastructure for compromised or abusive keys.
\end{enumerate}

\begin{exercise}
  Consider the broader implications: How would mandatory signing affect
  free speech, whistleblowing, and political dissent?
  What alternative approaches to bot detection might avoid these
  concerns?
\end{exercise}


\section{Sybil resistance and rate limiting}\label{BotSybilResistance}

\ltnote{%
  We introduce the Sybil attack as a fundamental challenge to bot detection.
  This creates contrast with the assumption that identity binding fully 
  solves the problem.
  Students should discern that economic and computational barriers, not just 
  cryptography, are essential for bot resistance.
}

\begin{exercise}
  Even with identity binding, a determined adversary might acquire multiple 
  identities (fake IDs, purchased accounts, compromised devices).
  How can we make large-scale bot operation economically infeasible?
\end{exercise}

\subsection{The Sybil attack}

In a Sybil attack, an adversary creates many pseudonymous identities to gain 
disproportionate influence.
Even with identity verification:
\begin{itemize}
  \item Fake or stolen identity documents exist.
  \item \enquote{Device farms} provide many attested devices cheaply.
  \item Account markets sell verified accounts.
\end{itemize}

The goal is not to make bot operation impossible, but to make it expensive 
enough to deter most attackers.

\subsection{Proof-of-work requirements}

One approach is to require computational work for each signature:
\begin{enumerate}
  \item Before posting, the client must solve a computational puzzle 
    (similar to Bitcoin mining, but much easier).
  \item The puzzle difficulty is tuned so legitimate users barely notice 
    (e.g., 100ms of computation), but operating 10,000 bots requires 
    significant resources.
  \item The puzzle can be bound to the message content, preventing 
    pre-computation.
\end{enumerate}

\begin{exercise}
  What are the trade-offs of proof-of-work for bot deterrence?
\end{exercise}

Trade-offs:
\begin{description}
  \item[Energy cost] Proof-of-work consumes energy; environmental concerns 
    apply.
  \item[Device inequality] Powerful devices complete puzzles faster; this 
    disadvantages users with older phones.
  \item[Accessibility] Assistive technologies may struggle with computational 
    requirements.
  \item[Determined attackers] Well-funded adversaries (nation-states) can 
    afford the computation.
\end{description}

\subsection{Economic rate limiting}

Alternative approaches impose economic costs:
\begin{description}
  \item[Micropayments] Each post costs a tiny amount (e.g., \$0.001).
    Negligible for humans, prohibitive at bot scale.
  \item[Stake-based reputation] Users deposit a bond that is slashed for 
    violations.
    Sybil accounts require capital for each identity.
  \item[Social graph analysis] Accounts without genuine social connections 
    (mutual follows, conversations) face higher scrutiny.
\end{description}

\subsection{Consequences}

\begin{enumerate}
  \item No single mechanism eliminates Sybil attacks; defense in depth is 
    required.
  \item Economic barriers shift the problem from cryptography to economics.
  \item Accessibility and equity concerns constrain the aggressiveness of 
    rate limiting.
  \item Well-funded adversaries may accept the costs; the goal is deterrence, 
    not perfect prevention.
\end{enumerate}


\section{Legal and regulatory considerations}\label{BotLegal}

\ltnote{%
  We introduce legal aspects to create contrast with the purely technical 
  focus of previous sections.
  Students should discern that cryptographic systems operate within legal 
  frameworks that constrain design choices.
}

\begin{exercise}
  What legal and regulatory issues arise from mandatory signing of social 
  media posts?
\end{exercise}

\subsection{Privacy regulations}

In jurisdictions with strong privacy laws (EU GDPR, California CCPA):
\begin{description}
  \item[Data minimization] Collecting cryptographic signatures that link all 
    user activity may violate data minimization principles.
  \item[Right to erasure] Users may request deletion of their data, but 
    signatures on public posts create permanent links.
  \item[Consent] Users must understand and consent to the privacy implications 
    of signing.
\end{description}

\subsection{Free speech implications}

Mandatory identity verification conflicts with anonymous speech:
\begin{itemize}
  \item Whistleblowers and dissidents rely on anonymity for safety.
  \item Anonymous speech has legal protection in many democracies.
  \item Platforms operating globally must navigate varying legal regimes.
\end{itemize}

\begin{exercise}
  How might a platform balance bot detection with anonymous speech 
  protections?
\end{exercise}

Possible approaches:
\begin{itemize}
  \item Tiered verification: anonymous accounts exist but have reduced 
    visibility/reach.
  \item Verified accounts receive a badge; unverified accounts are not banned 
    but are marked.
  \item Group signatures allow proving membership without revealing identity 
    (as discussed in \cref{BotPrivacy}).
\end{itemize}

\subsection{Liability and content moderation}

If signatures provide non-repudiation:
\begin{itemize}
  \item Platforms may be compelled to provide signing key information to law 
    enforcement.
  \item Users may face legal consequences for signed content more easily.
  \item Platforms may face pressure to act on signed content as \enquote{known} 
    to be from a specific person.
\end{itemize}

\subsection{Consequences}

\begin{enumerate}
  \item Legal constraints may prohibit the most effective technical solutions.
  \item Privacy-by-design is not optional but legally mandated in some 
    jurisdictions.
  \item Global platforms must implement jurisdiction-specific policies.
  \item The design must be reviewed by legal counsel, not just engineers.
\end{enumerate}


\section{Future work and open problems}\label{BotFutureWork}

Several aspects of bot detection via signatures remain active areas of 
research:

\begin{description}
  \item[Decentralized identity (DIDs)] Self-sovereign identity systems could 
    provide verified credentials without centralized CAs.
    Users control their own identity data while still proving uniqueness.
  \item[Behavioral biometrics] Typing patterns, mouse movements, and 
    interaction timing could complement cryptographic verification.
    These are harder for bots to fake but raise additional privacy concerns.
  \item[Federated platforms] In decentralized social networks (Mastodon, 
    Bluesky), each server has different policies.
    Cross-server signature verification and identity portability are open 
    problems.
  \item[AI-generated content labeling] As AI-generated text becomes 
    indistinguishable from human writing, signatures prove human authorship 
    only if the signing process is secure.
  \item[Post-quantum signatures] Like camera signatures, social media 
    signatures should plan for quantum resistance.
    The high volume of signatures makes efficiency critical.
  \item[Incentive alignment] Economic mechanism design could make honest 
    behavior more profitable than bot operation, rather than relying solely 
    on detection.
\end{description}

\begin{exercise}
  Choose one of the topics above and outline how you would approach designing a 
  solution.
  What cryptographic primitives would you use?
  What are the main challenges?
\end{exercise}


\section*{Acknowledgements}

This chapter was written by Daniel Bosk with the assistance of Dan-Claude van 
Thropic.